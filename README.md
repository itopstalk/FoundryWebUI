# FoundryWebUI

A web-based chat interface for **Microsoft Foundry Local**, hosted on IIS. Think of it as a self-hosted [Open WebUI](https://github.com/open-webui/open-webui) alternative built with ASP.NET Core â€” designed to run on Windows Server alongside your local LLM inference engine.

> **Note**: This project supports **Foundry Local only**. Ollama is not supported.

![Platform](https://img.shields.io/badge/platform-Windows%20Server%202025-blue)
![Framework](https://img.shields.io/badge/.NET-8.0-purple)
![License](https://img.shields.io/badge/license-MIT-green)

## Features

- **ğŸ’¬ Chat Interface** â€” Conversational UI with streaming responses (Server-Sent Events), message history, and basic Markdown rendering
- **ğŸ“¦ Model Management** â€” Browse the full Foundry Local catalog (40+ models), download with progress tracking, and remove downloaded models
- **âœ… Can Run Indicator** â€” Estimates RAM requirements for each model and shows whether your system can run it
- **ğŸ”Œ Foundry Local Connection** â€” Bright green/red status indicator with endpoint display and reconnect button
- **ğŸ” Auto-Discovery** â€” Automatically detects the Foundry Local endpoint via CLI or port scanning
- **ğŸŒ™ Dark Theme** â€” Bootstrap 5 dark mode UI optimized for extended use
- **ğŸš€ IIS Hosted** â€” Runs as an in-process IIS application with zero external dependencies beyond .NET

## Architecture

```
Browser â”€â”€â”€â”€ HTTP/SSE â”€â”€â”€â”€â–¶ IIS + ASP.NET Core
                                â”‚
                                â–¼
                         Foundry Local
                        (port 5273)
```

| Component | Role |
|---|---|
| **Razor Pages** | Chat (`/`) and Models (`/Models`) pages |
| **API Controller** | REST + SSE endpoints under `/api/` |
| **FoundryLocalService** | Adapter for Foundry Local REST API + CLI (`foundry model download`, `foundry cache remove`) |
| **ILlmProvider** | Provider interface for extensibility |

## Quick Start

### Prerequisites

- Windows Server 2025 (or Windows 10/11)
- [.NET 8.0 SDK](https://dotnet.microsoft.com/download/dotnet/8.0)
- [Microsoft Foundry Local](https://www.foundrylocal.ai/) (installed via `winget install Microsoft.FoundryLocal`)

### Run locally (development)

```powershell
cd C:\Projects\FoundryWebUI

# Ensure Foundry Local is running
foundry service start

# Run the app
dotnet run
```

Open `http://localhost:5207` in your browser.

### Deploy to IIS (production)

```powershell
# Use the automated installer (elevated PowerShell)
.\Install-FoundryWebUI.ps1

# Or publish manually
dotnet publish -c Release -o C:\inetpub\FoundryWebUI
```

See [DEPLOYMENT.md](DEPLOYMENT.md) for the full step-by-step guide, including all prerequisite installation commands for a fresh Windows Server 2025.

### Update an existing deployment

After pulling the latest changes from Git, simply re-run the installer:

```powershell
git reset --hard origin/main   # if local changes exist
git pull
.\Install-FoundryWebUI.ps1
```

The script auto-detects existing installations and:
- Skips prerequisite installation (IIS, .NET, Foundry Local)
- Stops the IIS site, rebuilds from source, and redeploys
- **Preserves your `appsettings.json` customizations** (e.g., Foundry endpoint, CLI path)
- Auto-detects and configures the Foundry CLI path for IIS

## API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/status` | Provider health check |
| `GET` | `/api/system-info` | System RAM info (for "Can Run" estimates) |
| `GET` | `/api/models` | List all models (downloaded + catalog) |
| `GET` | `/api/models/loaded` | List only currently loaded/ready models |
| `POST` | `/api/chat?provider=foundry` | Streaming chat completion (SSE) |
| `POST` | `/api/models/download` | Download a model with progress (SSE) |
| `DELETE` | `/api/models/{modelId}` | Remove a downloaded model from cache |
| `POST` | `/api/reconnect` | Re-discover Foundry Local endpoint |

### Chat request example

```json
POST /api/chat?provider=foundry
Content-Type: application/json

{
  "model": "phi-3.5-mini",
  "messages": [
    { "role": "user", "content": "What is Foundry Local?" }
  ],
  "stream": true,
  "temperature": 0.7
}
```

## Configuration

Edit `appsettings.json`:

```json
{
  "LlmProviders": {
    "Foundry": {
      "Endpoint": "",
      "CliPath": ""
    }
  }
}
```

| Setting | Default | Notes |
|---|---|---|
| `Foundry:Endpoint` | *(blank â€” auto-detect)* | Set explicitly (e.g., `http://localhost:5273`) if auto-detection fails from IIS |
| `Foundry:CliPath` | *(blank â€” auto-detect)* | Full path to `foundry.exe`. Required for model download/remove from IIS. The installer sets this automatically |

### Finding the Foundry CLI path

If the installer doesn't auto-detect it, find it manually:

```powershell
Get-Command foundry | Select-Object Source
```

Set the result in `appsettings.json` (use double backslashes in JSON):

```json
"CliPath": "C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\WindowsApps\\foundry.exe"
```

## Project Structure

```
FoundryWebUI/
â”œâ”€â”€ Controllers/
â”‚   â””â”€â”€ ApiController.cs          # REST + SSE API endpoints
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ LlmModels.cs              # DTOs (ChatMessage, ModelInfo, etc.)
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ ILlmProvider.cs           # Provider interface
â”‚   â””â”€â”€ FoundryLocalService.cs    # Foundry Local adapter (API + CLI)
â”œâ”€â”€ Pages/
â”‚   â”œâ”€â”€ Index.cshtml              # Chat page with status panel
â”‚   â”œâ”€â”€ Models.cshtml             # Model management (download/remove)
â”‚   â””â”€â”€ Shared/_Layout.cshtml     # Shared layout (dark theme, status indicator)
â”œâ”€â”€ wwwroot/
â”‚   â”œâ”€â”€ css/site.css              # Custom styles
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ site.js               # Foundry status check + reconnect
â”‚       â”œâ”€â”€ chat.js               # Chat UI logic + SSE streaming
â”‚       â””â”€â”€ models.js             # Model listing, download, remove
â”œâ”€â”€ Program.cs                    # App startup and DI configuration
â”œâ”€â”€ appsettings.json              # Configuration (endpoint + CLI path)
â”œâ”€â”€ web.config                    # IIS hosting configuration
â”œâ”€â”€ Install-FoundryWebUI.ps1      # Automated deployment script
â””â”€â”€ DEPLOYMENT.md                 # Full deployment & troubleshooting guide
```

## Troubleshooting

| Symptom | Likely Cause | Fix |
|---|---|---|
| Foundry shows red indicator in nav bar | Foundry Local not running or unreachable | Start it: `foundry service start` |
| No models listed | Foundry Local not connected | Check endpoint in appsettings.json or click ğŸ”„ Reconnect on home page |
| Download fails: "foundry CLI not found" | IIS can't find `foundry.exe` | Set `CliPath` in appsettings.json (see Configuration) |
| Remove fails | Wrong CLI command or CLI not found | Ensure `CliPath` is set; uses `foundry cache remove` |
| HTTP 500.30 on IIS | Hosting Bundle not installed | See [DEPLOYMENT.md â€” Troubleshooting](DEPLOYMENT.md#troubleshooting) |
| Chat shows no response | JSON casing mismatch or model not loaded | Check IIS stdout logs; ensure a model is loaded |
| Can't access from other machines | Windows Firewall blocking port | `New-NetFirewallRule -DisplayName "FoundryWebUI" -Direction Inbound -Protocol TCP -LocalPort 80 -Action Allow` |

For the complete troubleshooting guide, see [DEPLOYMENT.md](DEPLOYMENT.md#troubleshooting).

## Roadmap

- [ ] **Phase 2**: Conversation persistence (save/load chat history)
- [ ] **Phase 2**: System prompt customization
- [ ] **Phase 2**: Model parameter tuning (temperature, top_p, max_tokens)
- [ ] **Phase 3**: Multi-user support with session isolation
- [ ] **Phase 3**: File upload and document Q&A
- [ ] **Phase 3**: RAG (Retrieval-Augmented Generation) integration

## License

MIT
